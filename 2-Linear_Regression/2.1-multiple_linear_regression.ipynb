{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "060c1702",
   "metadata": {},
   "source": [
    "# üìò Multiple Linear Regression (MLR)\n",
    "\n",
    "## 1Ô∏è‚É£ Definition\n",
    "\n",
    "Multiple Linear Regression is a **supervised machine learning algorithm**\n",
    "used to predict a **continuous output** using **more than one input feature**.\n",
    "\n",
    "Unlike Simple Linear Regression (1 feature),\n",
    "Multiple Linear Regression uses **multiple features**.\n",
    "\n",
    "\n",
    "## 2Ô∏è‚É£ Model / Hypothesis Equation\n",
    "\n",
    "The hypothesis function for Multiple Linear Regression is:\n",
    "\n",
    "≈∑ = Œ∏‚ÇÄ + Œ∏‚ÇÅx‚ÇÅ + Œ∏‚ÇÇx‚ÇÇ + ... + Œ∏‚Çôx‚Çô\n",
    "\n",
    "Where:\n",
    "- ≈∑ ‚Üí predicted output\n",
    "- Œ∏‚ÇÄ ‚Üí intercept\n",
    "- Œ∏‚ÇÅ, Œ∏‚ÇÇ, ..., Œ∏‚Çô ‚Üí coefficients (weights)\n",
    "- x‚ÇÅ, x‚ÇÇ, ..., x‚Çô ‚Üí input features\n",
    "- n ‚Üí number of features\n",
    "\n",
    "\n",
    "## 3Ô∏è‚É£ Vectorized Form (Compact Equation)\n",
    "\n",
    "The same equation can be written as:\n",
    "\n",
    "≈∑ = Œ∏·µÄX\n",
    "\n",
    "Where:\n",
    "- Œ∏ ‚Üí parameter vector\n",
    "- X ‚Üí feature vector\n",
    "- Œ∏·µÄ ‚Üí transpose of Œ∏\n",
    "\n",
    "This form is used in implementation for efficiency.\n",
    "\n",
    "\n",
    "## 4Ô∏è‚É£ Actual vs Predicted Value\n",
    "\n",
    "For each data point i:\n",
    "- Actual value ‚Üí y‚ÅΩ‚Å±‚Åæ\n",
    "- Predicted value ‚Üí ≈∑‚ÅΩ‚Å±‚Åæ\n",
    "\n",
    "Prediction error (residual):\n",
    "\n",
    "Error = ≈∑‚ÅΩ‚Å±‚Åæ ‚àí y‚ÅΩ‚Å±‚Åæ\n",
    "\n",
    "\n",
    "## 5Ô∏è‚É£ Cost Function (Mean Squared Error)\n",
    "\n",
    "The cost function measures how well the model fits the data.\n",
    "\n",
    "J(Œ∏) = (1 / 2m) Œ£·µ¢‚Çå‚ÇÅ·µê ( ≈∑‚ÅΩ‚Å±‚Åæ ‚àí y‚ÅΩ‚Å±‚Åæ )¬≤\n",
    "\n",
    "Where:\n",
    "- m ‚Üí number of training examples\n",
    "- Squaring removes negative values\n",
    "- 1 / 2m simplifies differentiation\n",
    "\n",
    "\n",
    "## 6Ô∏è‚É£ Objective of Training\n",
    "\n",
    "The aim of Multiple Linear Regression is to:\n",
    "\n",
    "Minimize J(Œ∏)\n",
    "\n",
    "That is:\n",
    "- Find optimal values of Œ∏‚ÇÄ, Œ∏‚ÇÅ, Œ∏‚ÇÇ, ..., Œ∏‚Çô\n",
    "- Such that prediction error is minimum\n",
    "\n",
    "## 7Ô∏è‚É£ Gradient Descent Algorithm\n",
    "\n",
    "Gradient Descent is used to minimize the cost function.\n",
    "\n",
    "General update rule:\n",
    "\n",
    "Œ∏‚±º := Œ∏‚±º ‚àí Œ± ( ‚àÇJ / ‚àÇŒ∏‚±º )\n",
    "\n",
    "Where:\n",
    "- Œ± ‚Üí learning rate\n",
    "- j = 0, 1, 2, ..., n\n",
    "\n",
    "\n",
    "## 8Ô∏è‚É£ Partial Derivative for Œ∏‚±º\n",
    "\n",
    "‚àÇJ / ‚àÇŒ∏‚±º = (1 / m) Œ£·µ¢‚Çå‚ÇÅ·µê ( ≈∑‚ÅΩ‚Å±‚Åæ ‚àí y‚ÅΩ‚Å±‚Åæ ) x‚±º‚ÅΩ‚Å±‚Åæ\n",
    "\n",
    "Update rule:\n",
    "\n",
    "Œ∏‚±º := Œ∏‚±º ‚àí Œ± (1 / m) Œ£·µ¢‚Çå‚ÇÅ·µê ( ≈∑‚ÅΩ‚Å±‚Åæ ‚àí y‚ÅΩ‚Å±‚Åæ ) x‚±º‚ÅΩ‚Å±‚Åæ\n",
    "\n",
    "\n",
    "## 9Ô∏è‚É£ Gradient Descent (Final Algorithm)\n",
    "\n",
    "Repeat until convergence:\n",
    "\n",
    "Œ∏‚ÇÄ := Œ∏‚ÇÄ ‚àí Œ± (1 / m) Œ£ ( ≈∑ ‚àí y )\n",
    "\n",
    "Œ∏‚ÇÅ := Œ∏‚ÇÅ ‚àí Œ± (1 / m) Œ£ ( ≈∑ ‚àí y ) x‚ÇÅ\n",
    "\n",
    "Œ∏‚ÇÇ := Œ∏‚ÇÇ ‚àí Œ± (1 / m) Œ£ ( ≈∑ ‚àí y ) x‚ÇÇ\n",
    "\n",
    "...\n",
    "\n",
    "Œ∏‚Çô := Œ∏‚Çô ‚àí Œ± (1 / m) Œ£ ( ≈∑ ‚àí y ) x‚Çô\n",
    "\n",
    "\n",
    "## üîü Geometrical Interpretation\n",
    "\n",
    "- Simple Linear Regression ‚Üí straight line (2D)\n",
    "- Multiple Linear Regression ‚Üí plane or hyperplane (3D or higher)\n",
    "\n",
    "The model fits a **best-fit hyperplane** to minimize error.\n",
    "\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ Assumptions of Multiple Linear Regression\n",
    "\n",
    "1. Linear relationship between features and output\n",
    "2. No multicollinearity between input features\n",
    "3. Errors are normally distributed\n",
    "4. Homoscedasticity (constant variance of errors)\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "- Uses **multiple input features**\n",
    "- Equation: ≈∑ = Œ∏‚ÇÄ + Œ∏‚ÇÅx‚ÇÅ + Œ∏‚ÇÇx‚ÇÇ + ... + Œ∏‚Çôx‚Çô\n",
    "- Cost function: Mean Squared Error\n",
    "- Optimized using Gradient Descent\n",
    "- Output is a **best-fit hyperplane**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
