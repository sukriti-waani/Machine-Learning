{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129d363a",
   "metadata": {},
   "source": [
    "**Simple Linear Regression** is a supervised machine learning algorithm used to predict a continuous output using only one input feature.\n",
    "It finds a straight-line relationship between an independent variable (X) and a dependent variable (Y).\n",
    "\n",
    "#### What it does\n",
    "- You give the model one input value (X)\n",
    "- The model predicts one output value (Y)\n",
    "- The prediction is done using a straight line\n",
    "\n",
    "Example: \n",
    "Input (X): Study hours \n",
    "Output (Y): Marks obtained \n",
    "\n",
    "### Mathematical Equation\n",
    "The straight-line equation used is:  \n",
    "y=mx+c\n",
    "\n",
    "Where:\n",
    "y ‚Üí Predicted output, x ‚Üí Input feature, m ‚Üí Slope of the line (how much y changes when x changes), c ‚Üí Intercept (value of y when x = 0)\n",
    "\n",
    "#### Key Components\n",
    "- Independent Variable (X): Input feature\n",
    "- Dependent Variable (Y): Output to predict\n",
    "- Regression Line: Best-fit straight line through data points\n",
    "- **Error (Residual)**: Difference between actual value and predicted value\n",
    "\n",
    "### Objective\n",
    "The goal of simple linear regression is to find the best values of m and c such that the prediction error is minimum (usually by minimizing Mean Squared Error).\n",
    "\n",
    "üîπ *Real-World Examples*\n",
    "- Predicting house price based on area\n",
    "- Predicting salary based on years of experience\n",
    "- Predicting marks based on study hours\n",
    "\n",
    "üîπ *When to use Simple Linear Regression*\n",
    "- Only one input feature\n",
    "- Relationship between X and Y is linear\n",
    "- Output is continuous (not categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2cd0f",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Model / Hypothesis Equation\n",
    "In Simple Linear Regression, we assume a **linear relationship** between input `x` and output `y`.\n",
    "\n",
    "The model (hypothesis) is:\n",
    "\n",
    "h(x) = Œ∏‚ÇÄ + Œ∏‚ÇÅx\n",
    "\n",
    "Where:\n",
    "- h(x) ‚Üí predicted output\n",
    "- x ‚Üí input feature\n",
    "- Œ∏‚ÇÄ ‚Üí intercept (value of y when x = 0)\n",
    "- Œ∏‚ÇÅ ‚Üí slope (change in y for 1 unit change in x)\n",
    "\n",
    "This is similar to the straight-line equation:\n",
    "\n",
    "y = mx + c\n",
    "\n",
    "### **predicted points ***≈∑ = h(x)***\n",
    "\n",
    "### **ERROR = y - ≈∑**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f985a",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Predicted vs Actual Value\n",
    "\n",
    "For each data point:\n",
    "- Actual value ‚Üí y‚ÅΩ‚Å±‚Åæ\n",
    "- Predicted value ‚Üí h(x‚ÅΩ‚Å±‚Åæ)\n",
    "\n",
    "Prediction error (residual):\n",
    "\n",
    "Error = h(x‚ÅΩ‚Å±‚Åæ) ‚àí y‚ÅΩ‚Å±‚Åæ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5878e4c3",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Cost Function (Mean Squared Error)\n",
    "\n",
    "To measure how good the line fits the data, we use a **cost function**.\n",
    "\n",
    "Cost function J(Œ∏‚ÇÄ, Œ∏‚ÇÅ):\n",
    "\n",
    "J(Œ∏‚ÇÄ, Œ∏‚ÇÅ) = (1 / 2m) Œ£·µ¢‚Çå‚ÇÅ·µê ( h(x‚ÅΩ‚Å±‚Åæ) ‚àí y‚ÅΩ‚Å±‚Åæ )¬≤\n",
    "\n",
    "Where:\n",
    "- m ‚Üí number of training examples\n",
    "- Œ£ ‚Üí summation\n",
    "- Squaring ensures all errors are positive\n",
    "- 1/2m simplifies differentiation\n",
    "\n",
    "\n",
    "## 4Ô∏è‚É£ Objective of Training\n",
    "\n",
    "The goal of Simple Linear Regression is:\n",
    "\n",
    "Minimize J(Œ∏‚ÇÄ, Œ∏‚ÇÅ)\n",
    "\n",
    "That means:\n",
    "- Find the best Œ∏‚ÇÄ and Œ∏‚ÇÅ\n",
    "- Such that prediction error is minimum\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a24357",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Gradient Descent (Optimization Algorithm)\n",
    "\n",
    "Gradient Descent is used to minimize the cost function.\n",
    "\n",
    "General update rule:\n",
    "\n",
    "Œ∏‚±º := Œ∏‚±º ‚àí Œ± ( ‚àÇJ / ‚àÇŒ∏‚±º )\n",
    "\n",
    "Where:\n",
    "- Œ± (alpha) ‚Üí learning rate (small positive value)\n",
    "- ‚àÇJ / ‚àÇŒ∏‚±º ‚Üí partial derivative of cost function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411aeaba",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Partial Derivative for Œ∏‚ÇÄ\n",
    "\n",
    "‚àÇJ / ‚àÇŒ∏‚ÇÄ = (1 / m) Œ£·µ¢‚Çå‚ÇÅ·µê ( h(x‚ÅΩ‚Å±‚Åæ) ‚àí y‚ÅΩ‚Å±‚Åæ )\n",
    "\n",
    "Update rule:\n",
    "\n",
    "Œ∏‚ÇÄ := Œ∏‚ÇÄ ‚àí Œ± (1 / m) Œ£·µ¢‚Çå‚ÇÅ·µê ( h(x‚ÅΩ‚Å±‚Åæ) ‚àí y‚ÅΩ‚Å±‚Åæ )\n",
    "\n",
    "\n",
    "## 7Ô∏è‚É£ Partial Derivative for Œ∏‚ÇÅ\n",
    "\n",
    "‚àÇJ / ‚àÇŒ∏‚ÇÅ = (1 / m) Œ£·µ¢‚Çå‚ÇÅ·µê ( h(x‚ÅΩ‚Å±‚Åæ) ‚àí y‚ÅΩ‚Å±‚Åæ ) x‚ÅΩ‚Å±‚Åæ\n",
    "\n",
    "Update rule:\n",
    "\n",
    "Œ∏‚ÇÅ := Œ∏‚ÇÅ ‚àí Œ± (1 / m) Œ£·µ¢‚Çå‚ÇÅ·µê ( h(x‚ÅΩ‚Å±‚Åæ) ‚àí y‚ÅΩ‚Å±‚Åæ ) x‚ÅΩ‚Å±‚Åæ\n",
    "\n",
    "\n",
    "## 8Ô∏è‚É£ Gradient Descent Algorithm (Final Form)\n",
    "\n",
    "Repeat until convergence:\n",
    "\n",
    "Œ∏‚ÇÄ := Œ∏‚ÇÄ ‚àí Œ± (1 / m) Œ£·µ¢‚Çå‚ÇÅ·µê ( h(x‚ÅΩ‚Å±‚Åæ) ‚àí y‚ÅΩ‚Å±‚Åæ )\n",
    "\n",
    "Œ∏‚ÇÅ := Œ∏‚ÇÅ ‚àí Œ± (1 / m) Œ£·µ¢‚Çå‚ÇÅ·µê ( h(x‚ÅΩ‚Å±‚Åæ) ‚àí y‚ÅΩ‚Å±‚Åæ ) x‚ÅΩ‚Å±‚Åæ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbbc7c6",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Convergence\n",
    "\n",
    "Convergence means:\n",
    "- Cost function J becomes minimum\n",
    "- Œ∏‚ÇÄ and Œ∏‚ÇÅ stop changing significantly\n",
    "- The regression line becomes the **best-fit line**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
