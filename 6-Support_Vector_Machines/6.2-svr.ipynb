{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee89443",
   "metadata": {},
   "source": [
    "# üìò Support Vector Regression (SVR)\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ What is SVR?\n",
    "\n",
    "Support Vector Regression (SVR) is the **regression version of Support Vector Machines**.\n",
    "\n",
    "It tries to fit the best line (or curve) such that **most data points lie inside a margin tube** instead of separating classes.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Œµ ‚Äì Epsilon Tube\n",
    "\n",
    "SVR creates a tube around the regression line.\n",
    "\n",
    "- Upper boundary:   w·µÄx + b + Œµ  \n",
    "- Lower boundary:   w·µÄx + b ‚àí Œµ  \n",
    "\n",
    "Points **inside the tube are ignored**.  \n",
    "Only points outside this margin are penalized.\n",
    "\n",
    "(Shown in diagram on page 4 ‚Äì epsilon margin around line) :contentReference[oaicite:1]{index=1}\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Support Vectors in SVR\n",
    "\n",
    "Support vectors are the **points lying on or outside the Œµ-tube**.\n",
    "\n",
    "These points determine the position of the regression line.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Cost Function of SVR\n",
    "\n",
    "Objective:\n",
    "\n",
    "Minimize:\n",
    "\n",
    "||w||¬≤ / 2  +  C Œ£ Œæ·µ¢\n",
    "\n",
    "Where:  \n",
    "- ||w||¬≤ / 2 ‚Üí controls flatness of the regression line  \n",
    "- Œæ·µ¢ ‚Üí penalty for points outside epsilon margin  \n",
    "- C ‚Üí regularization parameter (controls overfitting)\n",
    "\n",
    "(Shown in cost function diagram on page 4) :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ SVR Constraints\n",
    "\n",
    "For every point:\n",
    "\n",
    "| y·µ¢ ‚àí (w·µÄx·µ¢ + b) | ‚â§ Œµ + Œæ·µ¢\n",
    "\n",
    "Where:  \n",
    "- Œµ ‚Üí margin error (tube width)  \n",
    "- Œæ·µ¢ ‚Üí error outside margin\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Role of C (Regularization Parameter)\n",
    "\n",
    "| C Value | Effect |\n",
    "|-------|--------|\n",
    "| Small C | Larger margin, more tolerance, underfitting |\n",
    "| Large C | Smaller margin, strict fitting, overfitting |\n",
    "\n",
    "(Graph shown on page 4 ‚Äì relationship between C and loss) :contentReference[oaicite:3]{index=3}\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Comparison: SVC vs SVR\n",
    "\n",
    "| Feature | SVC | SVR |\n",
    "|-------|-----|-----|\n",
    "| Task | Classification | Regression |\n",
    "| Margin | Separates classes | Œµ-tube around regression line |\n",
    "| Loss | Hinge Loss | Œµ-insensitive loss |\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- SVR predicts continuous values.\n",
    "- Uses **Œµ-insensitive margin**.\n",
    "- Only points outside tube contribute to loss.\n",
    "- Controlled by parameters **C and Œµ**.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
