{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29864872",
   "metadata": {},
   "source": [
    "# üìò Logistic Regression (Binary Classification)\n",
    "\n",
    "## 1Ô∏è‚É£ What is Logistic Regression?\n",
    "\n",
    "Logistic Regression is a **classification algorithm** used when the output has\n",
    "**only two categories**.\n",
    "\n",
    "Example:\n",
    "Study Hours ‚Üí Pass / Fail\n",
    "\n",
    "Output values:\n",
    "- Pass  ‚Üí 1  \n",
    "- Fail  ‚Üí 0\n",
    "\n",
    "\n",
    "## 2Ô∏è‚É£ Why Linear Regression Cannot Be Used for Classification?\n",
    "\n",
    "If we apply linear regression for classification:\n",
    "\n",
    "- Predictions can become **greater than 1** or **less than 0**\n",
    "- Output cannot be interpreted as probability\n",
    "- Highly sensitive to outliers\n",
    "\n",
    "Therefore, Linear Regression is **not suitable for classification problems**.\n",
    "\n",
    "\n",
    "## 3Ô∏è‚É£ Logistic Regression Hypothesis\n",
    "\n",
    "Linear part:\n",
    "\n",
    "z = Œ∏‚ÇÄ + Œ∏‚ÇÅx\n",
    "\n",
    "Sigmoid Function:\n",
    "\n",
    "œÉ(z) = 1 / (1 + e‚Åª·∂ª)\n",
    "\n",
    "Logistic Regression Hypothesis:\n",
    "\n",
    "h(x) = œÉ(Œ∏‚ÇÄ + Œ∏‚ÇÅx)\n",
    "     = 1 / (1 + e‚Åª·∂ª)\n",
    "\n",
    "\n",
    "## 4Ô∏è‚É£ Decision Boundary\n",
    "\n",
    "If:\n",
    "\n",
    "h(x) ‚â• 0.5  ‚Üí Predict 1  \n",
    "h(x) < 0.5  ‚Üí Predict 0\n",
    "\n",
    "\n",
    "## 5Ô∏è‚É£ Cost Function Problem\n",
    "\n",
    "Linear Regression cost function is:\n",
    "\n",
    "J(Œ∏) = (1 / 2m) Œ£ ( h(x‚ÅΩ‚Å±‚Åæ) ‚àí y‚ÅΩ‚Å±‚Åæ )¬≤\n",
    "\n",
    "This cost function becomes **non-convex** in logistic regression,\n",
    "so it is not suitable.\n",
    "\n",
    "\n",
    "## 6Ô∏è‚É£ Logistic Regression Cost Function (Log Loss)\n",
    "\n",
    "Cost for one training example:\n",
    "\n",
    "If y = 1:\n",
    "Cost = ‚àílog(h(x))\n",
    "\n",
    "If y = 0:\n",
    "Cost = ‚àílog(1 ‚àí h(x))\n",
    "\n",
    "\n",
    "## 7Ô∏è‚É£ Combined Cost Function\n",
    "\n",
    "Cost(h(x), y) = ‚àíy log(h(x)) ‚àí (1 ‚àí y) log(1 ‚àí h(x))\n",
    "\n",
    "\n",
    "## 8Ô∏è‚É£ Final Cost Function\n",
    "\n",
    "J(Œ∏‚ÇÄ, Œ∏‚ÇÅ) = ‚àí (1 / m) Œ£ [ y‚ÅΩ‚Å±‚Åæ log(h(x‚ÅΩ‚Å±‚Åæ)) \n",
    "                     + (1 ‚àí y‚ÅΩ‚Å±‚Åæ) log(1 ‚àí h(x‚ÅΩ‚Å±‚Åæ)) ]\n",
    "\n",
    "\n",
    "## 9Ô∏è‚É£ Optimization Using Gradient Descent\n",
    "\n",
    "We minimize the cost by updating Œ∏ values:\n",
    "\n",
    "Œ∏‚±º := Œ∏‚±º ‚àí Œ± ‚àÇ/‚àÇŒ∏‚±º J(Œ∏‚ÇÄ, Œ∏‚ÇÅ)\n",
    "\n",
    "Where:\n",
    "- Œ± ‚Üí learning rate\n",
    "- j ‚Üí 0,1\n",
    "\n",
    "\n",
    "## üîü Summary\n",
    "\n",
    "- Logistic Regression is used for **binary classification**\n",
    "- Uses **sigmoid function**\n",
    "- Output range is **0 to 1**\n",
    "- Linear Regression cannot be used because output is unbounded\n",
    "- Uses **log loss (cross entropy)** as cost function\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
