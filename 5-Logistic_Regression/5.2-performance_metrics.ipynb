{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98ad3f5",
   "metadata": {},
   "source": [
    "# üìò Performance Metrics ‚Äì Accuracy, Precision, Recall & F-Beta Score\n",
    "\n",
    "\n",
    "## 1Ô∏è‚É£ Topics Covered\n",
    "\n",
    "1. Confusion Matrix  \n",
    "2. Accuracy  \n",
    "3. Precision  \n",
    "4. Recall  \n",
    "5. F-Beta Score\n",
    "\n",
    "\n",
    "## 2Ô∏è‚É£ Confusion Matrix\n",
    "\n",
    "A Confusion Matrix shows the performance of a classification model.\n",
    "\n",
    "|               | Actual = 1 | Actual = 0 |\n",
    "|---------------|------------|------------|\n",
    "| Predicted = 1 | TP         | FP         |\n",
    "| Predicted = 0 | FN         | TN         |\n",
    "\n",
    "TP ‚Üí True Positive  \n",
    "FP ‚Üí False Positive  \n",
    "FN ‚Üí False Negative  \n",
    "TN ‚Üí True Negative\n",
    "\n",
    "\n",
    "## 3Ô∏è‚É£ Accuracy\n",
    "\n",
    "Accuracy tells how many predictions are correct.\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "\n",
    "## 4Ô∏è‚É£ Problem with Accuracy\n",
    "\n",
    "If dataset is imbalanced, accuracy becomes misleading.\n",
    "\n",
    "Example:\n",
    "- Total records = 1000  \n",
    "- 900 ‚Üí Class 1  \n",
    "- 100 ‚Üí Class 0  \n",
    "\n",
    "If model predicts all as Class 1:\n",
    "\n",
    "Accuracy = 900 / 1000 = 90% ‚ùå  \n",
    "But model is actually useless.\n",
    "\n",
    "\n",
    "## 5Ô∏è‚É£ Precision\n",
    "\n",
    "Precision answers:\n",
    "\n",
    "Out of all **predicted positives**, how many are actually correct?\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "\n",
    "## 6Ô∏è‚É£ Recall\n",
    "\n",
    "Recall answers:\n",
    "\n",
    "Out of all **actual positives**, how many did we correctly predict?\n",
    "\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "\n",
    "## 6Ô∏è‚É£ Recall\n",
    "\n",
    "Recall answers:\n",
    "\n",
    "Out of all **actual positives**, how many did we correctly predict?\n",
    "\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "\n",
    "## 7Ô∏è‚É£ Precision & Recall Example ‚Äì Spam Detection\n",
    "\n",
    "|               | Actual Spam | Actual Not Spam |\n",
    "|---------------|-------------|----------------|\n",
    "| Predicted Spam     | TP | FP |\n",
    "| Predicted Not Spam | FN | TN |\n",
    "\n",
    "- Precision ‚Üí How many emails predicted as spam are actually spam  \n",
    "- Recall ‚Üí How many real spam emails were detected\n",
    "\n",
    "\n",
    "\n",
    "## 8Ô∏è‚É£ Precision & Recall Example ‚Äì Disease Detection\n",
    "\n",
    "If:\n",
    "\n",
    "Truth ‚Üí Person has disease  \n",
    "Model ‚Üí Predicts no disease  \n",
    "\n",
    "This is a **False Negative (FN)** ‚Äì very dangerous mistake.\n",
    "\n",
    "\n",
    "## 9Ô∏è‚É£ F-Beta Score\n",
    "\n",
    "F-Beta Score combines Precision and Recall.\n",
    "\n",
    "FŒ≤ Score = (1 + Œ≤¬≤) √ó (Precision √ó Recall) / (Precision + Recall)\n",
    "\n",
    "\n",
    "## üîü F-1 Score (Œ≤ = 1)\n",
    "\n",
    "When both Precision and Recall are equally important:\n",
    "\n",
    "F1 Score = 2 √ó (Precision √ó Recall) / (Precision + Recall)\n",
    "\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ F-0.5 Score (FP is more important than FN)\n",
    "\n",
    "Œ≤ = 0.5  \n",
    "Used when False Positives are more costly.\n",
    "\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ F-2 Score (FN is more important than FP)\n",
    "\n",
    "Œ≤ = 2  \n",
    "Used when False Negatives are more dangerous.\n",
    "\n",
    "Example:\n",
    "- Disease detection  \n",
    "- Fraud detection\n",
    "\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "- Accuracy is not reliable for imbalanced datasets  \n",
    "- Precision focuses on **quality of positive predictions**  \n",
    "- Recall focuses on **detecting all actual positives**  \n",
    "- F-Beta balances Precision and Recall based on problem importance\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
